#!/usr/bin/env python3.5

import os, collections, sys, shutil, subprocess, re, cp437, hashlib, random

def print_count(l):
  c = collections.Counter(l)
  for name, count in c.most_common():
    print('{0: <5} {1}'.format(count, name))

def die(*args):
  if args:
    print(*args)
  sys.exit(-1)

commands = {}

def register(f):
  commands[f.__name__] = f

def replace_prefix(s, prefix, replacement):
  if not s.startswith(prefix):
    die('chomp: {} does not start with {}'.format(s, prefix))
  return replacement + s[len(prefix):]

@register
def unpack():
  problematic = []
  for root, subdirs, files in os.walk('dat/raw'):
    dst_root = replace_prefix(root, 'dat/raw', 'dat/unpacked')
    if not os.path.isdir(dst_root):
      os.makedirs(dst_root)
    for name in files:
      src = os.path.join(root, name)
      dst = os.path.join(dst_root, name)
      _, ext = os.path.splitext(name)
      if ext == '.zip':
        cmd = ['unzip', '-n', src, '-d', dst]
      elif ext == '.rar':
        os.makedirs(dst)
        cmd = ['unrar', 'e','-or', src, dst]
      elif ext == '.lzh' or ext == '.lha':
        cmd = ['lha', 'x', '-w', dst, src]
      elif ext == '.arj':
        cmd = ['arj', 'e', src, dst]
      elif ext == '.tgz':
        cmd = ['tar', 'zxvf', src, '-C', dst]
      else:
        cmd = ['cp', src, dst]
      print('running {}'.format(' '.join(cmd)))
      result = subprocess.call(cmd)
      if result != 0:
        print('{} failed!'.format(' '.join(cmd)))
        problematic.append(src)
  print()
  print('problematic:')
  for src in problematic:
    print(src)

CRLF      = re.compile(b'\r\n'                                   )
SGR       = re.compile(b'\x1B[[]([0-9;]*)m'                      )
CURSOR    = re.compile(b'\x1B[[]([0-9;,]*)(A|B|C|D||H|J|K|M|s|u)')
WHATEVER  = re.compile(b'\x1B[[]([^A-Za-z+-]*[A-Za-z+-])'        )

sgr_counter = collections.Counter()
esc_counter = collections.Counter()

good       = []
bad_width  = []
bad_data   = []
empty      = []
cursor     = []
text       = []
duplicates = {}

def writelines(dst, lines):
  with open(dst, 'w') as f:
    for line in lines:
      f.write(line + '\n')

emit_color = False

def translate(src, dst):
  with open(src, 'rb') as f:
    data = f.read()
  digest = hashlib.sha256(data).digest()
  if digest in duplicates:
    duplicates[digest].append(src)
    return
  else:
    duplicates[digest] = [src]
  s         = ''
  printable = 0
  lowercase = 0
  count     = len(data)
  x         = 0
  i         = 0
  bad       = False
  sgrs      = []
  bold      = 0
  italic    = 0
  underline = 0
  blink     = 0
  bg        = 0
  fg        = 7
  def color():
    if not emit_color:
      return ''
    nonlocal bold, fg, bg
    offset = bold & 0b1
    offset <<= 3
    offset |= fg & 0b111
    offset <<= 1
    offset |= blink & 0b1
    offset <<= 3
    offset |= bg & 0b111
    if offset < 0 or offset > 255:
      die('bad offset:', offset)
    return chr(0x2800 + offset)
  def endline():
    nonlocal s, x, bad, color
    if x > 80:
      print('bad width:', x, src)
      bad_width.append(src)
      bad = True
    s += (color() + ' ') * (80 - x)
    s += color() + '\n'
    x = 0
  while i < count and not bad:
    match = SGR.match(data, i)
    if match:
      payload = match.group(1).decode('utf-8')
      sgrs.append(payload)
      ns = [int(s) for s in payload.split(';') if s]
      for n in ns:
        if n == 0:
          bold = italic = underline = blink = 0
          bg = 0
          fg = 7
        elif n == 1:
          bold = 1
        elif n == 3:
          italic = 0
        elif n == 4:
          underline = 0
        elif n == 5:
          blink = 0
        elif n == 24:
          underline = 0
        elif n >= 30 and n <= 37:
          fg = n - 30
        elif n >= 40 and n <= 47:
          bg = n - 40
      i += len(match.group(0))
      continue
    match = CURSOR.match(data, i)
    if match:
      cursor.append(src)
      bad = True
      i += len(match.group(0))
      continue
    match = WHATEVER.match(data, i)
    if match:
      esc_counter[match.group(1)] += 1
      i += len(match.group(0))
      continue
    c = data[i]
    if c == 0x1B: # ESC
      print('stray escape character:', src)
      bad_data.append(src)
      bad = True
    elif c == 0x9: # TAB
      s += (color() + ' ') * 8
      x += 8
      i += 1
    elif c == 0xA: # LF
      endline()
      i += 1
    elif CRLF.match(data, i): # CRLF
      endline()
      i += 2
    elif c == 0x1A: # EOF
      endline()
      break
    else:
      if c != 0 and c != 32:
        printable += 1
      if c >= 97 and c <= 122:
        lowercase += 1
      s += color() + cp437.characters[c]
      x += 1
      i += 1
  if count == 0:
    empty.append(src)
    bad = True
  if s and s[-1] != '\n':
    endline()
  if bad:
    return
  if printable == 0:
    art_ratio = 1
  else:
    art_ratio = 1 - lowercase / printable
  if art_ratio < 0.50:
    text.append(src)
    return
  good.append(src)
  print('good:', src)
  sgr_counter.update(sgrs)
  with open(dst, 'wt') as f:
    f.write(s)

limit = False

@register
def clean():
  exts = set()
  i = 0
  for root, subdirs, files in os.walk('dat/artpacks'):
    if limit and i > 1000:
      break
    dst_root = replace_prefix(root, 'dat/artpacks', 'dat/clean')
    if not os.path.isdir(dst_root):
      os.makedirs(dst_root)
    for name in files:
      ext = os.path.splitext(name)[1][1:].lower()
      if ext not in {'ans', 'asc', 'ice'}:
        continue
      src = os.path.join(root, name)
      dst = os.path.join(dst_root, name)
      translate(src, dst)
      i += 1

  writelines('good.log',      good)
  writelines('bad-width.log', bad_width)
  writelines('bad-data.log',  bad_data)
  writelines('empty.log',     empty)
  writelines('cursor.log',    cursor)
  writelines('text.log',      text)
  writelines('sgr.log', ['{} {}'.format(s, n) for s, n in sgr_counter.most_common()])
  writelines('esc.log', ['{} {}'.format(e, n) for e, n in esc_counter.most_common()])
  lines = []
  for digest, paths in duplicates.items():
    if len(paths) == 1:
      continue
    for path in duplicates[digest]:
      lines.append(path)
    lines.append('')
  writelines('duplicates.log', lines)

@register
def classify():
  i = 0
  for root, subdirs, files in os.walk('dat/clean'):
    for name in files:
      if name == '.DS_Store':
        continue
      src = os.path.join(root, name)
      match = re.match('^dat/clean/(acid|ice|other)/([0-9]{4})/', src)
      if not match:
        die('no match:', src)
      group = match.group(1)
      year = int(match.group(2))
      ext = os.path.splitext(src)[1][1:].lower()
      dst = 'dat/classified/{}-{}-{}-{}.ans'.format(group, year, ext, i)
      shutil.copyfile(src, dst)
      i += 1

@register
def render():
  for root, subdirs, files in os.walk('dat/classified'):
    for name in files:
      src = os.path.join(root, name)
      dst = replace_prefix(src, 'dat/classified', 'dat/rendered')
      data = open(src, 'r').read()
      with open(dst, 'wb') as f:
        bold = 0
        fg   = 7
        bg   = 0
        for i in range(len(data)):
          c = data[i]
          n = ord(c)
          if emit_color and i % 2 == 0:
            offset = n - 0x2800
            if offset > 255 or offset < 0:
              sys.exit('bad offset', offset)
            bg = offset & 0b111
            offset >>= 3
            blink = offset & 0b1
            offset >>= 1
            fg = offset & 0b111
            offset >>= 3
            bold = offset & 0b1
          else:
            if c == '\n':
              pass
            else:
              if emit_color:
                f.write(b'\x1B[0m')
                if bold:
                  f.write(b'\x1B[1m')
                if blink:
                  f.write(b'\x1B[5m')
                f.write(b'\x1B' + '[{};{}m'.format(30 + fg, 40 + bg).encode('ascii'))
              original = cp437.codepoints.index(n)
              if original > 255:
                die('bad original:', original)
              f.write(bytes([original]))

def make_training_set(dst, srcs, target_size):
  random.shuffle(srcs)
  with open(dst, 'wb') as df:
    n = 0
    for src in srcs:
      if n >= target_size:
        break
      with open(src, 'rb') as sf:
        data = sf.read()
        n += len(data)
        df.write(data)

meg = 1 << 20

@register
def compile():
  srcs = []
  for root, subdirs, files in os.walk('dat/classified'):
    for name in files:
      srcs.append(os.path.join(root, name))
  make_training_set('dat/compiled/2.txt',   srcs,    2 * meg)
  make_training_set('dat/compiled/4.txt',   srcs,    4 * meg)
  make_training_set('dat/compiled/8.txt',   srcs,    8 * meg)
  make_training_set('dat/compiled/16.txt',  srcs,   16 * meg)
  make_training_set('dat/compiled/32.txt',  srcs,   32 * meg)
  make_training_set('dat/compiled/all.txt', srcs, 1000 * meg)

if len(sys.argv) != 2:
  die('usage: main COMMAND')

command = sys.argv[1]

if command in commands:
  print('{}ing...'.format(command))
  commands[command]()
else:
  die('unexpected command:', command)
